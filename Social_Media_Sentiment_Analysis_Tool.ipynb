{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy nltk textblob plotly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogiNCSwes6B1",
        "outputId": "5178a5c8-95d5-4ef7-eef9-c5fffe75344b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJWs1i-WseQR",
        "outputId": "399f850f-2800-4c27-95ff-be74f2fd8682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Product Quality Sentiment Analysis Summary:\n",
            "--------------------------------------------------\n",
            "Total tweets analyzed: 100\n",
            "Quality-related tweets: 16 (16.0%)\n",
            "\n",
            "Sentiment Distribution:\n",
            "sentiment_category\n",
            "positive    100.0\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# 1. Required Library Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import nltk\n",
        "from datetime import datetime\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "# 2. Download required NLTK data\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "class ProductSentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize sentiment analyzer with NLTK's VADER and TextBlob\n",
        "        \"\"\"\n",
        "        self.sia = SentimentIntensityAnalyzer()\n",
        "        self.quality_keywords = [\n",
        "            'quality', 'reliable', 'durability', 'durable', 'sturdy',\n",
        "            'build', 'construction', 'material', 'craftsmanship', 'made',\n",
        "            'manufacturing', 'defect', 'broken', 'issue', 'problem'\n",
        "        ]\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"\n",
        "        Clean and preprocess text data\n",
        "\n",
        "        Parameters:\n",
        "            text (str): Raw text\n",
        "        Returns:\n",
        "            str: Cleaned text\n",
        "        \"\"\"\n",
        "        # Convert to string in case of non-string input\n",
        "        text = str(text)\n",
        "\n",
        "        # Remove URLs\n",
        "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "        # Remove user mentions\n",
        "        text = re.sub(r'@\\w+', '', text)\n",
        "        # Remove hashtags\n",
        "        text = re.sub(r'#\\w+', '', text)\n",
        "        # Remove special characters and numbers\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        # Convert to lowercase\n",
        "        text = text.lower().strip()\n",
        "\n",
        "        return text\n",
        "\n",
        "    def is_quality_related(self, text):\n",
        "        \"\"\"\n",
        "        Check if tweet is related to product quality\n",
        "\n",
        "        Parameters:\n",
        "            text (str): Cleaned text\n",
        "        Returns:\n",
        "            bool: True if quality-related, False otherwise\n",
        "        \"\"\"\n",
        "        return any(keyword in text for keyword in self.quality_keywords)\n",
        "\n",
        "    def get_compound_sentiment(self, text):\n",
        "        \"\"\"\n",
        "        Calculate compound sentiment score using VADER\n",
        "\n",
        "        Parameters:\n",
        "            text (str): Cleaned text\n",
        "        Returns:\n",
        "            float: Compound sentiment score\n",
        "        \"\"\"\n",
        "        return self.sia.polarity_scores(text)['compound']\n",
        "\n",
        "    def analyze_sentiment(self, text):\n",
        "        \"\"\"\n",
        "        Determine sentiment category based on compound score\n",
        "\n",
        "        Parameters:\n",
        "            text (str): Cleaned text\n",
        "        Returns:\n",
        "            str: Sentiment category\n",
        "        \"\"\"\n",
        "        compound_score = self.get_compound_sentiment(text)\n",
        "        if compound_score >= 0.05:\n",
        "            return 'positive'\n",
        "        elif compound_score <= -0.05:\n",
        "            return 'negative'\n",
        "        else:\n",
        "            return 'neutral'\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function for sentiment analysis pipeline\n",
        "    \"\"\"\n",
        "    # Initialize analyzer\n",
        "    analyzer = ProductSentimentAnalyzer()\n",
        "\n",
        "    # Load and preprocess data\n",
        "    df = pd.read_csv('/content/Social_Media_Sentiment_Dataset__.csv')\n",
        "\n",
        "    # Clean tweets and add new columns\n",
        "    df['cleaned_text'] = df['Tweet'].apply(analyzer.clean_text)\n",
        "    df['is_quality'] = df['cleaned_text'].apply(analyzer.is_quality_related)\n",
        "    df['sentiment_score'] = df['cleaned_text'].apply(analyzer.get_compound_sentiment)\n",
        "    df['sentiment_category'] = df['cleaned_text'].apply(analyzer.analyze_sentiment)\n",
        "\n",
        "    # Convert date string to datetime\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "    # Filter quality-related tweets\n",
        "    quality_df = df[df['is_quality']].copy()\n",
        "\n",
        "    # Create daily sentiment aggregates\n",
        "    daily_sentiment = quality_df.groupby(quality_df['Date'].dt.date).agg({\n",
        "        'sentiment_score': 'mean',\n",
        "        'sentiment_category': lambda x: x.value_counts().index[0],\n",
        "        'Tweet': 'count'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Create visualizations\n",
        "    def create_trend_plot():\n",
        "        fig = go.Figure()\n",
        "\n",
        "        # Add sentiment score line\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=daily_sentiment['Date'],\n",
        "            y=daily_sentiment['sentiment_score'],\n",
        "            name='Average Sentiment',\n",
        "            line=dict(color='blue', width=2)\n",
        "        ))\n",
        "\n",
        "        # Add tweet volume bars\n",
        "        fig.add_trace(go.Bar(\n",
        "            x=daily_sentiment['Date'],\n",
        "            y=daily_sentiment['Tweet'],\n",
        "            name='Tweet Volume',\n",
        "            yaxis='y2',\n",
        "            opacity=0.3\n",
        "        ))\n",
        "\n",
        "        # Update layout\n",
        "        fig.update_layout(\n",
        "            title='Product Quality Sentiment Trend',\n",
        "            xaxis_title='Date',\n",
        "            yaxis_title='Sentiment Score',\n",
        "            yaxis2=dict(\n",
        "                title='Tweet Volume',\n",
        "                overlaying='y',\n",
        "                side='right'\n",
        "            ),\n",
        "            hovermode='x unified'\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_sentiment_distribution():\n",
        "        sentiment_dist = quality_df['sentiment_category'].value_counts()\n",
        "\n",
        "        fig = px.pie(\n",
        "            values=sentiment_dist.values,\n",
        "            names=sentiment_dist.index,\n",
        "            title='Distribution of Product Quality Sentiments'\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    # Generate and save visualizations\n",
        "    trend_fig = create_trend_plot()\n",
        "    dist_fig = create_sentiment_distribution()\n",
        "\n",
        "    # Save interactive HTML files\n",
        "    trend_fig.write_html('quality_sentiment_trend.html')\n",
        "    dist_fig.write_html('quality_sentiment_distribution.html')\n",
        "\n",
        "    # Print summary statistics\n",
        "    print(\"\\nProduct Quality Sentiment Analysis Summary:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Total tweets analyzed: {len(df)}\")\n",
        "    print(f\"Quality-related tweets: {len(quality_df)} ({len(quality_df)/len(df)*100:.1f}%)\")\n",
        "    print(\"\\nSentiment Distribution:\")\n",
        "    print(quality_df['sentiment_category'].value_counts(normalize=True).multiply(100).round(1))\n",
        "\n",
        "    # Save processed data\n",
        "    quality_df.to_csv('analyzed_quality_tweets.csv', index=False)\n",
        "    daily_sentiment.to_csv('daily_quality_sentiment.csv', index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}